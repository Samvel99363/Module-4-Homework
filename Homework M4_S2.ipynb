{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c948db53",
   "metadata": {},
   "source": [
    "# Module 4 — Session 2: Practical Exercises (Classification Metrics)\n",
    "\n",
    "This notebook follows the instructions from your **M4, S2_ Practical Exercises** file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8797ce3",
   "metadata": {},
   "source": [
    "## Exercise 1: The Metrics Calculator (Conceptual)\n",
    "\n",
    "A model was tested on a set of 100 patient records to predict a disease. The results are summarized in the following confusion matrix:\n",
    "\n",
    "|                | Predicted: No Disease | Predicted: Disease |\n",
    "|----------------|----------------------:|-------------------:|\n",
    "| **Actual: No Disease** | 85 | 5 |\n",
    "| **Actual: Disease**    | 8  | 2 |\n",
    "\n",
    "Tasks:\n",
    "1) Identify TP, TN, FP, FN  \n",
    "2) Calculate Accuracy  \n",
    "3) Calculate Precision  \n",
    "4) Calculate Recall  \n",
    "5) Calculate F1-Score  \n",
    "Show formulas and calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 (optional) — compute the metrics in Python (matches the manual work)\n",
    "TP = 2\n",
    "TN = 85\n",
    "FP = 5\n",
    "FN = 8\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5acc2b3",
   "metadata": {},
   "source": [
    "## Exercise 2: The Scikit-learn Report Card (Coding)\n",
    "\n",
    "**Setup:** Use the same notebook/code from Session 1. You should already have:\n",
    "- `X_train, X_test, y_train, y_test`\n",
    "- a trained `model`\n",
    "- `predictions = model.predict(X_test)`\n",
    "\n",
    "Import the necessary evaluation functions below, then run the tasks:\n",
    "- `classification_report`\n",
    "- confusion matrix + seaborn heatmap\n",
    "- ROC curve + AUC (needs probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49189775",
   "metadata": {},
   "source": [
    "### 2.1 Classification Report\n",
    "\n",
    "Run:\n",
    "- `print(classification_report(y_test, predictions))`\n",
    "\n",
    "Then in a Markdown cell, write down the **Precision, Recall, F1-score** for class **'1' (Survived)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure these variables exist from Session 1:\n",
    "# X_train, X_test, y_train, y_test, model\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8f805",
   "metadata": {},
   "source": [
    "### 2.2 Confusion Matrix (Seaborn Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6233a",
   "metadata": {},
   "source": [
    "### 2.3 ROC Curve and AUC\n",
    "\n",
    "ROC needs predicted probabilities:\n",
    "- `y_pred_proba = model.predict_proba(X_test)[:, 1]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddeed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # random guess line\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337a989",
   "metadata": {},
   "source": [
    "## Exercise 3: The Strategist (Critical Thinking)\n",
    "\n",
    "Write 2–3 sentences each:\n",
    "\n",
    "1) A situation where **Precision** is much more important than **Recall**  \n",
    "2) A situation where **Recall** is much more important than **Precision**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ebffe",
   "metadata": {},
   "source": [
    "### 3.1 Precision > Recall\n",
    "\n",
    "- **Scenario:** Spam detection / email filtering  \n",
    "- **Reasoning (2–3 sentences):** We want to be very confident before labeling an email as spam, because a false positive can hide an important message (bank alerts, password resets, job offers). It’s better to let a bit of spam into the inbox than to mistakenly block a critical email, so precision matters most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84c94b",
   "metadata": {},
   "source": [
    "### 3.2 Recall > Precision\n",
    "\n",
    "- **Scenario:** Screening for a serious disease (e.g., cancer screening)  \n",
    "- **Reasoning (2–3 sentences):** In screening, missing a true case (false negative) can delay treatment and cause serious harm. It’s acceptable to flag some healthy patients for additional tests (false positives) if it ensures that most real cases are detected, so recall matters most."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
